{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRSW5ByEutra"
      },
      "source": [
        "# English Data Notebook\n",
        "\n",
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgCY4vznukTY"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction import text\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import (f1_score, accuracy_score, recall_score,\n",
        "                             precision_score, confusion_matrix, classification_report)\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from joblib import dump"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8gFyidGvOGv"
      },
      "source": [
        "## Import Datasets\n",
        "from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvXJy0HSvHPo",
        "outputId": "0a08b494-7e57-4417-9162-bab4153fa62a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CH3AfTA0vURf"
      },
      "outputs": [],
      "source": [
        "trainset_json = '/content/drive/My Drive/Thesis/Trainset/ML-ESG-3_Trainset_English.json'\n",
        "testset_json = '/content/drive/My Drive/Thesis/Testset/ML-ESG3_Testset_EN.json'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIXVap1MvUAe"
      },
      "source": [
        "Convert JSON files to dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "cCJnEccxvWbp"
      },
      "outputs": [],
      "source": [
        "with open(trainset_json, 'r') as file:\n",
        "    train_json_data = json.load(file)\n",
        "\n",
        "with open(testset_json, 'r') as file:\n",
        "    test_json_data = json.load(file)\n",
        "\n",
        "train_df = pd.json_normalize(train_json_data)\n",
        "test_df = pd.json_normalize(test_json_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 985
        },
        "id": "Bajo0vLg2Ywh",
        "outputId": "2cfb52bb-b4bc-49da-d5c2-739c547fb699"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-d9efbd076fbd>:1: FutureWarning:\n",
            "\n",
            "Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "\n",
            "<ipython-input-14-d9efbd076fbd>:1: FutureWarning:\n",
            "\n",
            "The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
            "\n",
            "<ipython-input-14-d9efbd076fbd>:2: FutureWarning:\n",
            "\n",
            "Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "\n",
            "<ipython-input-14-d9efbd076fbd>:2: FutureWarning:\n",
            "\n",
            "The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
            "\n",
            "<ipython-input-14-d9efbd076fbd>:3: FutureWarning:\n",
            "\n",
            "Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "\n",
            "<ipython-input-14-d9efbd076fbd>:4: FutureWarning:\n",
            "\n",
            "Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   URL  \\\n",
              "0    https://www.esgtoday.com/arabesque-ai-appoints...   \n",
              "1    https://www.esgtoday.com/arabesque-ai-appoints...   \n",
              "2    https://www.esgtoday.com/arabesque-ai-appoints...   \n",
              "3    https://www.esgtoday.com/ukraine-war-inflation...   \n",
              "4    https://www.esgtoday.com/eu-regulators-welcome...   \n",
              "..                                                 ...   \n",
              "540  https://www.esgtoday.com/methane-emissions-det...   \n",
              "541  https://www.esgtoday.com/eaton-appoints-harold...   \n",
              "542  https://www.esgtoday.com/ssga-outlines-2021-st...   \n",
              "543  https://www.esgtoday.com/survey-investors-shif...   \n",
              "544  https://www.esgtoday.com/chicago-to-transition...   \n",
              "\n",
              "                                            news_title  \\\n",
              "0    Arabesque AI Appoints Carolina Minio Paluello ...   \n",
              "1    Arabesque AI Appoints Carolina Minio Paluello ...   \n",
              "2    Arabesque AI Appoints Carolina Minio Paluello ...   \n",
              "3    Ukraine War, Inflation Reduction Act Driving F...   \n",
              "4    EU Regulators Welcome, Critique New European S...   \n",
              "..                                                 ...   \n",
              "540  Methane Emissions Detection Platform Kuva Rais...   \n",
              "541  Eaton Appoints Harold Jones as Chief Sustainab...   \n",
              "542  SSGA Outlines 2021 Stewardship Priorities, Wil...   \n",
              "543  Survey: Investors Shifting to Offense on Clima...   \n",
              "544  Chicago to Transition Buildings, Airports & Op...   \n",
              "\n",
              "                                          news_content impact_level  \\\n",
              "0    ESG-focused financial technology company Arabe...            0   \n",
              "1    The company also announced the appointment of ...            0   \n",
              "2    Wong said:  \\n“Personalised portfolios demand ...            1   \n",
              "3    One of the key themes of the report is the imp...            2   \n",
              "4    Europe’s three primary financial regulatory ag...            1   \n",
              "..                                                 ...          ...   \n",
              "540  Stefan Bokaemper, CEO of Kuva Systems, said: “...            0   \n",
              "541  Eaton Appoints Harold Jones as Chief Sustainab...            0   \n",
              "542  In his letter, Taraporevala wrote: “As a signa...            1   \n",
              "543  O’Brien said: “Investors globally are increasi...            0   \n",
              "544  Jim McHugh, Chief Commercial Officer, Constell...            1   \n",
              "\n",
              "    impact_length  \n",
              "0               1  \n",
              "1               1  \n",
              "2               1  \n",
              "3               2  \n",
              "4               0  \n",
              "..            ...  \n",
              "540             1  \n",
              "541             1  \n",
              "542             0  \n",
              "543             0  \n",
              "544             1  \n",
              "\n",
              "[545 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f975724c-485d-4c2a-be47-7859b4179475\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>URL</th>\n",
              "      <th>news_title</th>\n",
              "      <th>news_content</th>\n",
              "      <th>impact_level</th>\n",
              "      <th>impact_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.esgtoday.com/arabesque-ai-appoints...</td>\n",
              "      <td>Arabesque AI Appoints Carolina Minio Paluello ...</td>\n",
              "      <td>ESG-focused financial technology company Arabe...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.esgtoday.com/arabesque-ai-appoints...</td>\n",
              "      <td>Arabesque AI Appoints Carolina Minio Paluello ...</td>\n",
              "      <td>The company also announced the appointment of ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://www.esgtoday.com/arabesque-ai-appoints...</td>\n",
              "      <td>Arabesque AI Appoints Carolina Minio Paluello ...</td>\n",
              "      <td>Wong said:  \\n“Personalised portfolios demand ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://www.esgtoday.com/ukraine-war-inflation...</td>\n",
              "      <td>Ukraine War, Inflation Reduction Act Driving F...</td>\n",
              "      <td>One of the key themes of the report is the imp...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.esgtoday.com/eu-regulators-welcome...</td>\n",
              "      <td>EU Regulators Welcome, Critique New European S...</td>\n",
              "      <td>Europe’s three primary financial regulatory ag...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>540</th>\n",
              "      <td>https://www.esgtoday.com/methane-emissions-det...</td>\n",
              "      <td>Methane Emissions Detection Platform Kuva Rais...</td>\n",
              "      <td>Stefan Bokaemper, CEO of Kuva Systems, said: “...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>541</th>\n",
              "      <td>https://www.esgtoday.com/eaton-appoints-harold...</td>\n",
              "      <td>Eaton Appoints Harold Jones as Chief Sustainab...</td>\n",
              "      <td>Eaton Appoints Harold Jones as Chief Sustainab...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>542</th>\n",
              "      <td>https://www.esgtoday.com/ssga-outlines-2021-st...</td>\n",
              "      <td>SSGA Outlines 2021 Stewardship Priorities, Wil...</td>\n",
              "      <td>In his letter, Taraporevala wrote: “As a signa...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>543</th>\n",
              "      <td>https://www.esgtoday.com/survey-investors-shif...</td>\n",
              "      <td>Survey: Investors Shifting to Offense on Clima...</td>\n",
              "      <td>O’Brien said: “Investors globally are increasi...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>544</th>\n",
              "      <td>https://www.esgtoday.com/chicago-to-transition...</td>\n",
              "      <td>Chicago to Transition Buildings, Airports &amp; Op...</td>\n",
              "      <td>Jim McHugh, Chief Commercial Officer, Constell...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>545 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f975724c-485d-4c2a-be47-7859b4179475')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f975724c-485d-4c2a-be47-7859b4179475 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f975724c-485d-4c2a-be47-7859b4179475');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6becb1ed-0c1e-4e70-813e-c9e2901e7b95\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6becb1ed-0c1e-4e70-813e-c9e2901e7b95')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6becb1ed-0c1e-4e70-813e-c9e2901e7b95 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_24c192d7-3e2f-4164-a32c-d135407fb376\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_24c192d7-3e2f-4164-a32c-d135407fb376 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 545,\n  \"fields\": [\n    {\n      \"column\": \"URL\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 339,\n        \"samples\": [\n          \"https://www.esgtoday.com/six-launches-gender-equality-index/\",\n          \"https://www.esgtoday.com/green-steel-startup-h2gs-raises-105-million-in-equity-financing/\",\n          \"https://www.esgtoday.com/activist-shareholders-win-spots-on-exxon-board-as-demand-for-climate-action-accelerates/\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"news_title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 339,\n        \"samples\": [\n          \"SIX Launches Gender Equality Index\",\n          \"Green Steel Startup H2GS Raises $105 Million in Equity Financing\",\n          \"Activist Shareholders Win Spots on Exxon Board as Demand for Climate Action Accelerates\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"news_content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 545,\n        \"samples\": [\n          \"In its proxy filing, the company stated: \\u201cBeginning in 2021, an environmental, social, and governance modifier based on Apple Values and other key community initiatives will be incorporated into our annual cash incentive program. This change is intended to further motivate Apple\\u2019s executive team to meet exceptionally high standards of values-driven leadership in addition to delivering strong financial results.\\u201d\",\n          \"Daniel Hanna, Barclays Global Head of Sustainable Finance for the CIB, said: \\n\\u201cBarclays is uniquely positioned to help scale the new climate technologies that will decarbonise industries and create green jobs. Many of the technologies that are required to achieve Net Zero have not yet reached commercial scale. Barclays can play a critical role though leveraging our experience as an advisor, bank, and investor through our Sustainable Impact Capital Programme to help accelerate their development and adoption.\\u201c\",\n          \"DHL Supply Chain, the world\\u2019s leading contract logistics provider, expands its logistics service offerings with a new solutions suite for recovery management, especially relevant for tech companies. The new circular supply chain solution supports companies in enabling appropriate reuse, reprocessing, or recycling of used electronic parts e.g. like processors, touchscreens, computer modules or tech assets. By implementing new business models to reduce electronic waste, so-called e-waste, companies can lower their environmental impact and avoid the loss of scarce raw materials. As an industry leader, DHL can offer this recovery service alongside the entire supply chain globally.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"impact_level\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"impact_length\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "train_df[\"impact_level\"] = train_df[\"impact_level\"].replace([\"low\",\"medium\",\"high\"],[0,1,2])\n",
        "train_df[\"impact_length\"] = train_df[\"impact_length\"].replace([\"Less than 2 years\",\"2 to 5 years\",\"More than 5 years\"],[0,1,2])\n",
        "test_df[\"impact_level\"] = test_df[\"impact_level\"].replace([\"low\",\"medium\",\"high\"],[0,1,2])\n",
        "test_df[\"impact_length\"] = test_df[\"impact_length\"].replace([\"Less than 2 years\",\"2 to 5 years\",\"More than 5 years\"],[0,1,2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s23Tt1X0TQ0c"
      },
      "source": [
        "## Split the Training an Validation Set\n",
        "The Dataset now will be splitted into two datasets. The training set and the validation set. The test set it is already in a different dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YD4iuUtVTRCD"
      },
      "outputs": [],
      "source": [
        "levels = train_df.impact_level\n",
        "train_inputs, val_inputs, train_level, val_level = train_test_split(train_df, levels, test_size=0.2, stratify=levels )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "823hsmD75hH7"
      },
      "outputs": [],
      "source": [
        "train_inputs = train_inputs.news_content\n",
        "val_inputs = val_inputs.news_content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGbGkaBf2glH"
      },
      "source": [
        "## TF-IDF\n",
        "\n",
        "TF-IDF is a way to turn words into numbers so computers can understand them better. It looks at how often a word appears in a document and compares it to how often it appears in all the other documents. Words that are common in many documents (like \"the\" or \"and\") are given a lower score, while words that are rare but important (like \"artificial intelligence\" or \"quantum computing\") are given a higher score. This helps computers understand which words are most important in a document and can be used for things like sorting documents or finding related topics.\n",
        "\n",
        "### Selected Parameters and Their Justifications:\n",
        "lowercase=True:\n",
        "\n",
        "Reason: Text data can have case variations that represent the same word (e.g., \"Data\" vs. \"data\"). To ensure consistency and avoid treating these as different terms, converting all text to lowercase is important. This helps reduce the dimensionality of the feature space and improve model accuracy by treating the same words consistently.\n",
        "tokenizer=custom_tokenizer:\n",
        "\n",
        "Reason: A custom tokenizer can be used to better handle the nuances of your text data, especially if you need to account for special symbols, remove punctuation, or split on specific characters. This offers more control over how the text is processed, allowing the TF-IDF representation to focus on meaningful words or phrases.\n",
        "Example: You could define a tokenizer that removes URLs, handles numbers, or splits based on certain characters relevant to your task.\n",
        "ngram_range=(1, 2):\n",
        "\n",
        "Reason: This specifies that both unigrams (individual words) and bigrams (two consecutive words) will be considered as features. Using bigrams in addition to unigrams captures more context and can reveal important word pairings or common phrases that provide additional meaning beyond single words.\n",
        "Example: For a corpus where phrases like \"climate change\" or \"data science\" are highly relevant, including bigrams can improve the feature set and the model’s understanding of key terms.\n",
        "stop_words='english':\n",
        "\n",
        "Reason: Stop words are common words (e.g., \"and\", \"the\", \"is\") that are usually irrelevant to the specific meaning of the document. Removing these helps reduce the noise in the data, allowing the TF-IDF to focus on more informative terms. The 'english' stop word list in sklearn is widely used and includes the most common stop words for English text.\n",
        "Example: Removing stop words ensures that terms like \"data\" and \"science\" remain prominent in your vectorized data, while less informative words like \"and\" or \"the\" are discarded.\n",
        "max_df=0.85:\n",
        "\n",
        "Reason: This parameter excludes words that appear in more than 85% of the documents, assuming that such words are too common to be informative. These could be domain-specific stop words that don't add value to the analysis (e.g., \"said\" in news articles). This helps reduce dimensionality and focus on terms that are more unique to certain documents.\n",
        "Example: In a dataset of news articles, \"said\" or \"reported\" might appear in nearly every document, so excluding them helps reduce noise.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boyePeCTC4JK",
        "outputId": "3673a3b8-8126-4545-c9d7-60ccd6253671"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "english_stopwords = stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "SRFJqhm11PH2",
        "outputId": "36d00952-4ee3-48a2-9638-a8d0fe15de5f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"i,me,my,myself,we,our,ours,ourselves,you,you're,you've,you'll,you'd,your,yours,yourself,yourselves,he,him,his,himself,she,she's,her,hers,herself,it,it's,its,itself,they,them,their,theirs,themselves,what,which,who,whom,this,that,that'll,these,those,am,is,are,was,were,be,been,being,have,has,had,having,do,does,did,doing,a,an,the,and,but,if,or,because,as,until,while,of,at,by,for,with,about,against,between,into,through,during,before,after,above,below,to,from,up,down,in,out,on,off,over,under,again,further,then,once,here,there,when,where,why,how,all,any,both,each,few,more,most,other,some,such,no,nor,not,only,own,same,so,than,too,very,s,t,can,will,just,don,don't,should,should've,now,d,ll,m,o,re,ve,y,ain,aren,aren't,couldn,couldn't,didn,didn't,doesn,doesn't,hadn,hadn't,hasn,hasn't,haven,haven't,isn,isn't,ma,mightn,mightn't,mustn,mustn't,needn,needn't,shan,shan't,shouldn,shouldn't,wasn,wasn't,weren,weren't,won,won't,wouldn,wouldn't\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "\",\".join(english_stopwords)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eq-aoiCyK9u7"
      },
      "source": [
        "## Machine Learning Models\n",
        "As we can easily see, this project is a multi-class classification problem. For this reason we will use the belos **machine learning models**:\n",
        "\n",
        "\n",
        "*   Multinomial Logistic Regression\n",
        "*   Random Forest\n",
        "*   Support Vector Machines\n",
        "*   Naive Bayes\n",
        "*   Gradient Boosting Machines (XGBoost)\n",
        "\n",
        "We will conduct a grid search and evaluate the machine learning model using various parameters and different combinations. The grid search will identify the optimal combination of parameters that yields the highest F1 score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNAFP5D0Xb9g"
      },
      "source": [
        "### Multinomial Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "794n0H3whZua"
      },
      "outputs": [],
      "source": [
        "\n",
        "tfidf_params = {\n",
        "    'tfidf__lowercase': [True, False],\n",
        "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
        "    'tfidf__max_features': [ 500, 1000, 2000],\n",
        "    'tfidf__stop_words': [None, english_stopwords],\n",
        "}\n",
        "\n",
        "logistic_params = {\n",
        "    'logistic__C': [0.001, 0.01, 0.1, 1.0, 10.0],\n",
        "    'logistic__solver': ['lbfgs'],\n",
        "    'logistic__multi_class': ['multinomial'],\n",
        "    'logistic__class_weight': ['balanced']\n",
        "}\n",
        "\n",
        "param_grid = {**tfidf_params, **logistic_params}\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('logistic', LogisticRegression(max_iter=500))\n",
        "])\n",
        "\n",
        "grid_search = GridSearchCV(pipeline, param_grid, scoring='f1_macro', cv=5, verbose=2,  error_score='raise')\n",
        "grid_search.fit(train_inputs, train_level)\n",
        "\n",
        "print(\"Best combination of parameters are:\")\n",
        "print(grid_search.best_params_)\n",
        "print(f\"Best F1 score: {grid_search.best_score_}\")\n",
        "y_pred = grid_search.predict(val_inputs)\n",
        "f1 = f1_score(val_level, y_pred, average='macro')\n",
        "print(f\"Validation F1 score: {f1}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXQn70UXXU2Z"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxbqFkmJTrhd"
      },
      "outputs": [],
      "source": [
        "tfidf_params = {\n",
        "    'tfidf__lowercase': [True],\n",
        "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
        "    'tfidf__max_features': [2000, 3000, 5000],\n",
        "    'tfidf__stop_words': [None, english_stopwords],\n",
        "}\n",
        "\n",
        "\n",
        "rf_params = {\n",
        "    'rf__n_estimators': [50, 100],\n",
        "    'rf__max_depth': [5, 10, 15],\n",
        "    'rf__min_samples_split': [2, 5, 10],\n",
        "    'rf__min_samples_leaf': [1, 2, 4],\n",
        "    'rf__class_weight': ['balanced'],\n",
        "    'rf__bootstrap': [True]\n",
        "}\n",
        "\n",
        "param_grid = {**tfidf_params, **rf_params}\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('rf', RandomForestClassifier())\n",
        "])\n",
        "\n",
        "grid_search = GridSearchCV(pipeline, param_grid, scoring='f1_macro', cv=3, verbose=2)\n",
        "grid_search.fit(train_inputs, train_level)\n",
        "\n",
        "\n",
        "print(\"Best parameters set found:\")\n",
        "print(grid_search.best_params_)\n",
        "print(f\"Best F1 score: {grid_search.best_score_}\")\n",
        "y_pred = grid_search.predict(val_inputs)\n",
        "f1 = f1_score(val_level, y_pred, average='macro')\n",
        "print(f\"Validation F1 score: {f1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5uBnKlzXk5q"
      },
      "source": [
        "### Support Vector Machines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzhdWJLoYNso"
      },
      "outputs": [],
      "source": [
        "tfidf_params = {\n",
        "    'tfidf__lowercase': [True, False],\n",
        "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
        "    'tfidf__max_features': [1000, 2000, 5000],\n",
        "    'tfidf__stop_words': [None, english_stopwords]\n",
        "}\n",
        "\n",
        "svm_params = {\n",
        "    'svm__C': [0.01, 0.1, 1],\n",
        "    'svm__kernel': ['linear', 'rbf'],\n",
        "    'svm__gamma': ['scale', 'auto', 0.1, 0.01],\n",
        "    'svm__class_weight': ['balanced'],\n",
        "}\n",
        "\n",
        "param_grid = {**tfidf_params, **svm_params}\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('svm', SVC()),\n",
        "])\n",
        "\n",
        "grid_search = GridSearchCV(pipeline, param_grid, scoring='f1_macro', cv=5, verbose=2)\n",
        "\n",
        "\n",
        "grid_search.fit(train_inputs, train_level)\n",
        "\n",
        "print(\"Best parameters set found:\")\n",
        "print(grid_search.best_params_)\n",
        "print(f\"Best F1 score: {grid_search.best_score_}\")\n",
        "\n",
        "y_pred = grid_search.predict(val_inputs)\n",
        "f1 = f1_score(val_level, y_pred, average='macro')\n",
        "print(f\"Validation F1 score: {f1}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-tjxOjcXvZC"
      },
      "source": [
        "### Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HC38ZpyfCfM"
      },
      "outputs": [],
      "source": [
        "tfidf_params = {\n",
        "    'tfidf__lowercase': [True, False],\n",
        "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
        "    'tfidf__max_features': [1000, 2000, 5000],\n",
        "    'tfidf__stop_words': [None,  english_stopwords]\n",
        "}\n",
        "\n",
        "nb_params = {\n",
        "    'nb__alpha': [0.01, 0.05, 0.1, 0.5, 1.0, 5.0],\n",
        "}\n",
        "\n",
        "param_grid = {**tfidf_params, **nb_params}\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('nb', MultinomialNB()),\n",
        "])\n",
        "\n",
        "grid_search = GridSearchCV(pipeline, param_grid, scoring='f1_macro', cv=5, verbose=2)\n",
        "\n",
        "grid_search.fit(train_inputs, train_level)\n",
        "\n",
        "print(\"Best parameters set found:\")\n",
        "print(grid_search.best_params_)\n",
        "print(f\"Best F1 score: {grid_search.best_score_}\")\n",
        "\n",
        "y_pred = grid_search.predict(val_inputs)\n",
        "\n",
        "f1 = f1_score(val_level, y_pred, average='macro')\n",
        "print(f\"Validation F1 score: {f1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUhGsHQwX5xk"
      },
      "source": [
        "### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Dv4j3gCgTSt"
      },
      "outputs": [],
      "source": [
        "tfidf_params = {\n",
        "    'tfidf__lowercase': [True],\n",
        "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
        "    'tfidf__max_features': [500, 1000],  # Reduced features for testing\n",
        "    'tfidf__stop_words': [None, english_stopwords]\n",
        "}\n",
        "\n",
        "xgb_params = {\n",
        "    'xgb__n_estimators': [100, 200],\n",
        "    'xgb__max_depth': [3, 4, 5],\n",
        "    'xgb__learning_rate': [0.01, 0.05],\n",
        "    'xgb__gamma': [0.01],\n",
        "    'xgb__subsample': [0.7, 0.8, 1.0],\n",
        "}\n",
        "\n",
        "param_grid = {**tfidf_params, **xgb_params}\n",
        "\n",
        "# Define pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('xgb', XGBClassifier(eval_metric='mlogloss'))\n",
        "])\n",
        "\n",
        "# GridSearch with StratifiedKFold cross-validation\n",
        "grid_search = GridSearchCV(pipeline, param_grid, scoring='f1_macro', cv=StratifiedKFold(n_splits=2), verbose=2)\n",
        "\n",
        "# Fit the model\n",
        "grid_search.fit(train_inputs, train_level)\n",
        "\n",
        "# Output the best parameters and scores\n",
        "print(\"Best parameters set found:\")\n",
        "print(grid_search.best_params_)\n",
        "print(f\"Best F1 score: {grid_search.best_score_}\")\n",
        "\n",
        "# Evaluate on validation data\n",
        "y_pred = grid_search.predict(val_inputs)\n",
        "f1 = f1_score(val_level, y_pred, average='macro')\n",
        "print(f\"Validation F1 score: {f1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fmWID63h7z_"
      },
      "source": [
        "## Test Dataset\n",
        "\n",
        "In this section, we will evaluate all machine learning models that achieved the highest F1-score following hyperparameter tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmTD4gFgMh_C"
      },
      "outputs": [],
      "source": [
        "test_inputs = test_df.news_content\n",
        "test_labels = test_df.impact_level"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06jmi-FqVAkI"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gLvKHvMaefc"
      },
      "source": [
        "\n",
        "The selected hyperparameters for the Logistic Regression model contribute significantly to its outstanding performance, particularly evident in its highest F1-score among the tested models. The TF-IDF settings include 'lowercase' set to False, 'ngram_range' at (1, 1) for unigrams, and a tailored list of 'stop_words' (english_stopwords). This configuration helps the model focus on important features while reducing noise from common words. Additionally, the Logistic Regression parameters, with a regularization strength ('C') of 10.0, a 'multi_class' setting of 'multinomial', and the 'lbfgs' solver, effectively enhance its training for multi-class scenarios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGQyIrdyjSgq",
        "outputId": "e1194575-519f-45b7-f2e1-be98d7438284"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: 0.589295985866305\n",
            "Accuracy: 0.625\n",
            "Recall: 0.6018001550902846\n",
            "Precision: 0.5815871083673884\n",
            "Confusion Matrix:\n",
            " [[ 9  6  2]\n",
            " [ 9 33 17]\n",
            " [ 3 14 43]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.53      0.47        17\n",
            "           1       0.62      0.56      0.59        59\n",
            "           2       0.69      0.72      0.70        60\n",
            "\n",
            "    accuracy                           0.62       136\n",
            "   macro avg       0.58      0.60      0.59       136\n",
            "weighted avg       0.63      0.62      0.63       136\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning:\n",
            "\n",
            "'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tfidf_params = {\n",
        "    'lowercase': True,\n",
        "    'ngram_range': (1, 2),\n",
        "    'max_features': 1000,\n",
        "    'stop_words': english_stopwords\n",
        "    }\n",
        "\n",
        "logistic_params = {\n",
        "    'C': 0.1,\n",
        "    'multi_class': 'multinomial',\n",
        "    'solver': 'lbfgs',\n",
        "    'class_weight': 'balanced'\n",
        "}\n",
        "\n",
        "# Create the pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(**tfidf_params)),\n",
        "    ('logistic', LogisticRegression(**logistic_params))\n",
        "])\n",
        "\n",
        "# Train the model\n",
        "pipeline.fit(train_inputs, train_level)\n",
        "\n",
        "# Save the trained model\n",
        "dump(pipeline, 'trained_model.joblib')\n",
        "\n",
        "# Make predictions\n",
        "predictions = pipeline.predict(test_inputs)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "f1 = f1_score(test_labels, predictions, average='macro')\n",
        "accuracy = accuracy_score(test_labels, predictions)\n",
        "recall = recall_score(test_labels, predictions, average='macro')\n",
        "precision = precision_score(test_labels, predictions, average='macro')\n",
        "conf_matrix = confusion_matrix(test_labels, predictions)\n",
        "\n",
        "# Output results\n",
        "print(f\"F1 Score: {f1}\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", classification_report(test_labels, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjPLcCw4VHqz"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upJQyOUbbHZf"
      },
      "source": [
        "The chosen hyperparameters for the Random Forest model play a crucial role in enhancing its performance, as demonstrated by its notable F1-score among the models assessed. The TF-IDF configuration includes 'lowercase' set to True, which standardizes the text for uniformity, and an 'ngram_range' of (1, 2) that captures both unigrams and bigrams to enrich the feature set. By limiting the maximum number of features to 1000, the model focuses on the most significant terms, while the inclusion of a specified list of 'stop_words' (english_stopwords) minimizes noise from frequently used words. For the Random Forest parameters, utilizing 'class_weight' set to 'balanced' effectively addresses any class imbalance by adjusting weights based on class frequency. A 'max_depth' of 10 helps prevent overfitting by restricting the growth of individual trees, while 'min_samples_leaf' of 2 and 'min_samples_split' of 5 maintain a suitable balance between complexity and generalization. With 50 trees ('n_estimators'), the ensemble method enhances the model's predictive capabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DB0iUaBS5-O",
        "outputId": "ea31e487-0436-4c43-9b5a-3c2fe213faf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: 0.49235320586090436\n",
            "Accuracy: 0.5588235294117647\n",
            "Recall: 0.48229201285033785\n",
            "Precision: 0.5388396375098502\n",
            "Confusion Matrix:\n",
            " [[ 4 11  2]\n",
            " [ 4 41 14]\n",
            " [ 1 28 31]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.24      0.31        17\n",
            "           1       0.51      0.69      0.59        59\n",
            "           2       0.66      0.52      0.58        60\n",
            "\n",
            "    accuracy                           0.56       136\n",
            "   macro avg       0.54      0.48      0.49       136\n",
            "weighted avg       0.57      0.56      0.55       136\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tfidf_params = {\n",
        "    'lowercase': True,\n",
        "    'max_features': 5000,\n",
        "    'ngram_range': (1, 1),\n",
        "    'stop_words': None\n",
        "}\n",
        "\n",
        "rf_params = {\n",
        "    'bootstrap': True,\n",
        "    'class_weight': 'balanced',\n",
        "    'max_depth': 15,\n",
        "    'min_samples_leaf': 1,\n",
        "    'min_samples_split': 2,\n",
        "    'n_estimators': 100\n",
        "}\n",
        "\n",
        "# Create the pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(**tfidf_params)),\n",
        "    ('rf', RandomForestClassifier(**rf_params))\n",
        "])\n",
        "\n",
        "# Train the model\n",
        "pipeline.fit(train_inputs, train_level)\n",
        "\n",
        "# Save the trained model\n",
        "dump(pipeline, 'trained_model.joblib')\n",
        "\n",
        "# Make predictions\n",
        "predictions = pipeline.predict(test_inputs)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "f1 = f1_score(test_labels, predictions, average='macro')\n",
        "accuracy = accuracy_score(test_labels, predictions)\n",
        "recall = recall_score(test_labels, predictions, average='macro')\n",
        "precision = precision_score(test_labels, predictions, average='macro')\n",
        "conf_matrix = confusion_matrix(test_labels, predictions)\n",
        "\n",
        "# Output results\n",
        "print(f\"F1 Score: {f1}\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", classification_report(test_labels, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbaS2LwWPojV"
      },
      "source": [
        "### Support Vector Machine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mh_Nxu3YbOye"
      },
      "source": [
        "\n",
        "The hyperparameters selected for the Support Vector Machine (SVM) model significantly contribute to its effectiveness, as evidenced by its competitive F1-score among the evaluated models. The TF-IDF settings include 'lowercase' set to True, ensuring uniformity in the text data, and an 'ngram_range' of (1, 2), which captures both unigrams and bigrams to provide a richer representation of the features. By limiting the maximum number of features to 1000 and employing a tailored list of 'stop_words' (english_stopwords), the model effectively focuses on the most relevant terms while filtering out common noise. The SVM parameters include a regularization strength ('C') of 1, which balances the trade-off between maximizing the margin and minimizing classification errors. The 'class_weight' parameter is set to 'balanced', addressing any class imbalance by adjusting the weights of different classes accordingly. Additionally, 'gamma' set to 'scale' optimizes the influence of individual training examples, while the 'linear' kernel promotes simplicity and efficiency in separating the classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2fvgJl8Nz5C",
        "outputId": "2f0582cf-6cda-4d1c-a810-5924312385b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: 0.5806190476190477\n",
            "Accuracy: 0.6176470588235294\n",
            "Recall: 0.5827572837044422\n",
            "Precision: 0.5822973322973324\n",
            "Confusion Matrix:\n",
            " [[ 8  7  2]\n",
            " [ 7 39 13]\n",
            " [ 3 20 37]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.47      0.46        17\n",
            "           1       0.59      0.66      0.62        59\n",
            "           2       0.71      0.62      0.66        60\n",
            "\n",
            "    accuracy                           0.62       136\n",
            "   macro avg       0.58      0.58      0.58       136\n",
            "weighted avg       0.63      0.62      0.62       136\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tfidf_params = {\n",
        "    'lowercase': True,\n",
        "    'max_features': 2000,\n",
        "    'ngram_range': (1, 1),  # Unigrams\n",
        "    'stop_words': english_stopwords\n",
        "}\n",
        "\n",
        "svm_params = {\n",
        "    'C': 1,\n",
        "    'class_weight': 'balanced',\n",
        "    'gamma': 'scale',\n",
        "    'kernel': 'linear'\n",
        "}\n",
        "\n",
        "# Create a pipeline with TfidfVectorizer and SVM\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(**tfidf_params)),  # TF-IDF Vectorizer with parameters\n",
        "    ('svm', SVC(**svm_params))  # SVM Classifier with parameters\n",
        "])\n",
        "\n",
        "# Fit the pipeline on your training data\n",
        "pipeline.fit(train_inputs, train_level)\n",
        "\n",
        "# Save the fitted model\n",
        "dump(pipeline, 'trained_model.joblib')\n",
        "\n",
        "# Predict on the test dataset\n",
        "predictions = pipeline.predict(test_inputs)\n",
        "\n",
        "# Calculate metrics\n",
        "f1 = f1_score(test_labels, predictions, average='macro')\n",
        "accuracy = accuracy_score(test_labels, predictions)\n",
        "recall = recall_score(test_labels, predictions, average='macro')\n",
        "precision = precision_score(test_labels, predictions, average='macro')\n",
        "conf_matrix = confusion_matrix(test_labels, predictions)\n",
        "\n",
        "# Print results\n",
        "print(f\"F1 Score: {f1}\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", classification_report(test_labels, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8PhmPZVVjg0"
      },
      "source": [
        "### Multinomial Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwfPtRI-bRON"
      },
      "source": [
        "\n",
        "The hyperparameters chosen for the Naive Bayes (NB) model play a crucial role in its performance, as reflected in its F1-score among the other models tested. The TF-IDF configuration includes 'lowercase' set to True, ensuring consistent treatment of words, while the 'ngram_range' of (1, 2) allows the model to consider both unigrams and bigrams, enhancing its understanding of the context in which words appear. By setting the maximum number of features to 1000 and utilizing a tailored list of 'stop_words' (english_stopwords), the model can effectively highlight significant terms while filtering out common noise. The Naive Bayes parameter, 'alpha', is set to 0.1, which applies Laplace smoothing to handle zero probabilities, ensuring that all features contribute to the classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iQ4BN3DQjZc",
        "outputId": "84578a2b-b073-41e5-8cf0-619f33417eeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: 0.4860773181941065\n",
            "Accuracy: 0.5514705882352942\n",
            "Recall: 0.47654813337764484\n",
            "Precision: 0.5222222222222223\n",
            "Confusion Matrix:\n",
            " [[ 4 11  2]\n",
            " [ 6 39 14]\n",
            " [ 0 28 32]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.24      0.30        17\n",
            "           1       0.50      0.66      0.57        59\n",
            "           2       0.67      0.53      0.59        60\n",
            "\n",
            "    accuracy                           0.55       136\n",
            "   macro avg       0.52      0.48      0.49       136\n",
            "weighted avg       0.56      0.55      0.55       136\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tfidf_params = {\n",
        "    'lowercase': True,\n",
        "    'max_features': 1000,\n",
        "    'ngram_range': (1, 2),  # Unigrams and bigrams\n",
        "    'stop_words': english_stopwords\n",
        "}\n",
        "\n",
        "nb_params = {\n",
        "    'alpha': 0.05\n",
        "}\n",
        "\n",
        "# Create a pipeline with TfidfVectorizer and MultinomialNB\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(**tfidf_params)),  # TF-IDF Vectorizer with parameters\n",
        "    ('nb', MultinomialNB(**nb_params))  # Multinomial Naive Bayes Classifier with parameters\n",
        "])\n",
        "\n",
        "# Fit the pipeline on your training data\n",
        "pipeline.fit(train_inputs, train_level)\n",
        "\n",
        "# Save the fitted model\n",
        "dump(pipeline, 'trained_model.joblib')\n",
        "\n",
        "# Predict on the test dataset\n",
        "predictions = pipeline.predict(test_inputs)\n",
        "\n",
        "# Calculate metrics\n",
        "f1 = f1_score(test_labels, predictions, average='macro')\n",
        "accuracy = accuracy_score(test_labels, predictions)\n",
        "recall = recall_score(test_labels, predictions, average='macro')\n",
        "precision = precision_score(test_labels, predictions, average='macro')\n",
        "conf_matrix = confusion_matrix(test_labels, predictions)\n",
        "\n",
        "# Print results\n",
        "print(f\"F1 Score: {f1}\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", classification_report(test_labels, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmLr1QrbVaGd"
      },
      "source": [
        "### XG-Boost\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WoWt9tKbsYJ"
      },
      "source": [
        "\n",
        "The chosen hyperparameters for the XGBoost model play a crucial role in enhancing its classification performance. The TF-IDF settings include 'lowercase' set to True for consistent word representation, an 'ngram_range' of (1, 1) to focus on unigrams, and a limit of 500 maximum features to reduce complexity. The use of a tailored list of 'stop_words' (english_stopwords) helps remove common terms that contribute little to the model's effectiveness. The XGBoost parameters feature a 'gamma' of 0.1, which controls model complexity by penalizing new splits; a 'learning_rate' of 0.1 to moderate the influence of each tree; a 'max_depth' of 5 to prevent overfitting; and 'n_estimators' set to 100, determining the number of boosting rounds. Together, these hyperparameters enable the XGBoost model to effectively manage complexity and enhance its performance on the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYVVy3MxQ-eZ",
        "outputId": "6d17f10d-2759-472f-87c9-64f216ab4312"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: 0.36417342056439805\n",
            "Accuracy: 0.47794117647058826\n",
            "Recall: 0.37911820095269744\n",
            "Precision: 0.4101867572156197\n",
            "Confusion Matrix:\n",
            " [[ 1 14  2]\n",
            " [ 3 42 14]\n",
            " [ 1 37 22]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.20      0.06      0.09        17\n",
            "           1       0.45      0.71      0.55        59\n",
            "           2       0.58      0.37      0.45        60\n",
            "\n",
            "    accuracy                           0.48       136\n",
            "   macro avg       0.41      0.38      0.36       136\n",
            "weighted avg       0.48      0.48      0.45       136\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tfidf_params = {\n",
        "    'lowercase': True,\n",
        "    'max_features': 500,\n",
        "    'ngram_range': (1, 1),\n",
        "    'stop_words': english_stopwords\n",
        "}\n",
        "\n",
        "xgb_params = {\n",
        "    'gamma': 0.01,\n",
        "    'learning_rate': 0.05,\n",
        "    'max_depth': 4,\n",
        "    'n_estimators': 200,\n",
        "    'subsample': 1.0\n",
        "}\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(**tfidf_params)),\n",
        "    ('xgb', XGBClassifier(**xgb_params))\n",
        "])\n",
        "\n",
        "pipeline.fit(train_inputs, train_level)\n",
        "dump(pipeline, 'trained_model.joblib')\n",
        "predictions = pipeline.predict(test_inputs)\n",
        "\n",
        "f1 = f1_score(test_labels, predictions, average='macro')\n",
        "accuracy = accuracy_score(test_labels, predictions)\n",
        "recall = recall_score(test_labels, predictions, average='macro')\n",
        "precision = precision_score(test_labels, predictions, average='macro')\n",
        "conf_matrix = confusion_matrix(test_labels, predictions)\n",
        "\n",
        "print(f\"F1 Score: {f1}\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", classification_report(test_labels, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hsh48-HBVoY-"
      },
      "source": [
        "Let's now compare all the results and find which of these Machine Learning models give us the best results. To remind we had a train dataset which was multi class, spwcifically with three classes and was moderate imbalance. Let's firstly compare the f1-score :\n",
        "\n",
        "| Model        | Train Dataset | Validation Dataset | Test Dataset |\n",
        "|--------------|---------------|--------------------|--------------|\n",
        "| Logistic Regression (LR) | 0.542         | 0.519              | 0.589 ⭐     |\n",
        "| Random Forest (RF)       | 0.513         | 0.549 ⭐           | 0.492       |\n",
        "| Support Vector Machine (SVM) | 0.538         | 0.545              | 0.580       |\n",
        "| Naive Bayes (NB)        | 0.550 ⭐      | 0.527              | 0.486       |\n",
        "| XGBoost                 | 0.435         | 0.498              | 0.364       |\n",
        "\n",
        "\n",
        "In this analysis, the performance of various machine learning models was compared using F1 scores across training, validation, and test datasets. Logistic Regression (LR) emerged as the best performer overall, achieving an F1 score of 0.589 on the test dataset, indicating robust generalization. Random Forest (RF) led the validation dataset with a score of 0.549, but showed a decline to 0.492 on the test dataset, suggesting potential overfitting. Support Vector Machine (SVM) maintained balanced performance across all datasets, with scores ranging from 0.538 (train) to 0.580 (test). Naive Bayes (NB) excelled in the training dataset (0.550) but experienced a drop in performance on validation and test datasets, highlighting its limitations in handling imbalanced classes. Conversely, XGBoost consistently underperformed, scoring 0.364 on the test dataset, indicating that its current hyperparameters may not be suitable for this multi-class, moderately imbalanced task. Overall, while LR proved to be the strongest candidate, there is room for improvement in tuning parameters and exploring techniques to address class imbalance, particularly for the models that struggled."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrbMcXU1HDeF"
      },
      "source": [
        "Although the best models identified are Logistic Regression (LR) and Support Vector Machine (SVM), both the F1 score and accuracy remain relatively low. Therefore, further hyperparameter tuning will be performed, focusing solely on the SVM model. The results obtained from the training set are as follows:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import spacy\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "stemmer = PorterStemmer()\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQpY2yDxctzL",
        "outputId": "b8f5770e-7d9a-4ffa-82fa-927bdee64708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LR with stemming"
      ],
      "metadata": {
        "id": "Sj-qxOUzjqw3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBKIGy9PQcVr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec1ed2e3-2d6f-45cf-dc62-7f805e5d8461"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:406: UserWarning:\n",
            "\n",
            "Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'becaus', 'befor', 'could', 'doe', 'dure', 'ha', 'hi', 'might', 'must', 'need', 'onc', 'onli', 'ourselv', 'sha', 'themselv', 'thi', 'veri', 'wa', 'whi', 'wo', 'would', 'yourselv'] not in stop_words.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning:\n",
            "\n",
            "'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score on Training Set: 0.8176446119462991\n",
            "F1 Score on Validation Set: 0.5313399778516058\n",
            "F1 Score on Test Set: 0.566467958271237\n",
            "Accuracy: 0.5882352941176471\n",
            "Recall: 0.5876980170599314\n",
            "Precision: 0.5549001274188964\n",
            "Confusion Matrix:\n",
            " [[10  5  2]\n",
            " [11 29 19]\n",
            " [ 2 17 41]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.59      0.50        17\n",
            "           1       0.57      0.49      0.53        59\n",
            "           2       0.66      0.68      0.67        60\n",
            "\n",
            "    accuracy                           0.59       136\n",
            "   macro avg       0.55      0.59      0.57       136\n",
            "weighted avg       0.59      0.59      0.59       136\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def stem_tokens(tokens):\n",
        "    return [stemmer.stem(token) for token in tokens]\n",
        "\n",
        "def preprocessor(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    stemmed = stem_tokens(tokens)\n",
        "    return ' '.join(stemmed)\n",
        "\n",
        "tfidf_params = {\n",
        "    'lowercase': True,\n",
        "    'ngram_range': (1, 2),\n",
        "    'max_features': 1000,\n",
        "    'stop_words': english_stopwords,\n",
        "    'preprocessor': preprocessor\n",
        "}\n",
        "\n",
        "logistic_params = {\n",
        "    'C': 0.1,\n",
        "    'multi_class': 'multinomial',\n",
        "    'solver': 'lbfgs',\n",
        "    'class_weight': 'balanced'\n",
        "}\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(**tfidf_params)),\n",
        "    ('logistic', LogisticRegression(**logistic_params))\n",
        "])\n",
        "\n",
        "pipeline.fit(train_inputs, train_level)\n",
        "dump(pipeline, 'trained_model.joblib')\n",
        "\n",
        "train_preds = pipeline.predict(train_inputs)\n",
        "val_preds = pipeline.predict(val_inputs)\n",
        "test_preds = pipeline.predict(test_inputs)\n",
        "\n",
        "f1_train = f1_score(train_level, train_preds, average='macro')\n",
        "f1_val = f1_score(val_level, val_preds, average='macro')\n",
        "f1_test = f1_score(test_labels, test_preds, average='macro')\n",
        "print(f\"F1 Score on Training Set: {f1_train}\")\n",
        "print(f\"F1 Score on Validation Set: {f1_val}\")\n",
        "print(f\"F1 Score on Test Set: {f1_test}\")\n",
        "\n",
        "accuracy = accuracy_score(test_labels, test_preds)\n",
        "recall = recall_score(test_labels, test_preds, average='macro')\n",
        "precision = precision_score(test_labels, test_preds, average='macro')\n",
        "conf_matrix = confusion_matrix(test_labels, test_preds)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", classification_report(test_labels, test_preds))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "with lemmatization\n"
      ],
      "metadata": {
        "id": "u9vFSmxyklMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatize_text_spacy(text):\n",
        "    doc = nlp(text)\n",
        "    return ' '.join([token.lemma_ for token in doc])\n",
        "\n",
        "tfidf_params = {\n",
        "    'lowercase': True,\n",
        "    'ngram_range': (1, 2),\n",
        "    'max_features': 1000,\n",
        "    'stop_words': english_stopwords,\n",
        "    'preprocessor': lemmatize_text_spacy\n",
        "}\n",
        "\n",
        "logistic_params = {\n",
        "    'C': 0.1,\n",
        "    'multi_class': 'multinomial',\n",
        "    'solver': 'lbfgs',\n",
        "    'class_weight': 'balanced'\n",
        "}\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(**tfidf_params)),\n",
        "    ('logistic', LogisticRegression(**logistic_params))\n",
        "])\n",
        "\n",
        "pipeline.fit(train_inputs, train_level)\n",
        "dump(pipeline, 'trained_model.joblib')\n",
        "\n",
        "train_preds = pipeline.predict(train_inputs)\n",
        "val_preds = pipeline.predict(val_inputs)\n",
        "test_preds = pipeline.predict(test_inputs)\n",
        "\n",
        "f1_train = f1_score(train_level, train_preds, average='macro')\n",
        "f1_val = f1_score(val_level, val_preds, average='macro')\n",
        "f1_test = f1_score(test_labels, test_preds, average='macro')\n",
        "print(f\"F1 Score on Training Set: {f1_train}\")\n",
        "print(f\"F1 Score on Validation Set: {f1_val}\")\n",
        "print(f\"F1 Score on Test Set: {f1_test}\")\n",
        "\n",
        "accuracy = accuracy_score(test_labels, test_preds)\n",
        "recall = recall_score(test_labels, test_preds, average='macro')\n",
        "precision = precision_score(test_labels, test_preds, average='macro')\n",
        "conf_matrix = confusion_matrix(test_labels, test_preds)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", classification_report(test_labels, test_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgGLuNsGh2nc",
        "outputId": "90d06773-e852-4b00-b75c-885d28ed8258"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning:\n",
            "\n",
            "'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score on Training Set: 0.8413046772596117\n",
            "F1 Score on Validation Set: 0.5609308831272859\n",
            "F1 Score on Test Set: 0.5477503518496817\n",
            "Accuracy: 0.5588235294117647\n",
            "Recall: 0.5794339204608397\n",
            "Precision: 0.53315649867374\n",
            "Confusion Matrix:\n",
            " [[11  4  2]\n",
            " [12 28 19]\n",
            " [ 3 20 37]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.42      0.65      0.51        17\n",
            "           1       0.54      0.47      0.50        59\n",
            "           2       0.64      0.62      0.63        60\n",
            "\n",
            "    accuracy                           0.56       136\n",
            "   macro avg       0.53      0.58      0.55       136\n",
            "weighted avg       0.57      0.56      0.56       136\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "with stemming and lemmatization"
      ],
      "metadata": {
        "id": "i-DRFk2nkZM6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n",
        "\n",
        "def lemmatize_and_stem(text):\n",
        "    doc = nlp(text)\n",
        "    lemmatized_words = [token.lemma_ for token in doc]\n",
        "\n",
        "    stemmed_words = [stemmer.stem(word) for word in lemmatized_words]\n",
        "\n",
        "    return ' '.join(stemmed_words)\n",
        "\n",
        "tfidf_params = {\n",
        "    'lowercase': True,\n",
        "    'ngram_range': (1, 2),\n",
        "    'max_features': 1000,\n",
        "    'stop_words': english_stopwords,\n",
        "    'preprocessor': lemmatize_and_stem\n",
        "}\n",
        "\n",
        "logistic_params = {\n",
        "    'C': 0.1,\n",
        "    'multi_class': 'multinomial',\n",
        "    'solver': 'lbfgs',\n",
        "    'class_weight': 'balanced'\n",
        "}\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(**tfidf_params)),\n",
        "    ('logistic', LogisticRegression(**logistic_params))\n",
        "])\n",
        "\n",
        "pipeline.fit(train_inputs, train_level)\n",
        "dump(pipeline, 'trained_model.joblib')\n",
        "\n",
        "train_preds = pipeline.predict(train_inputs)\n",
        "val_preds = pipeline.predict(val_inputs)\n",
        "test_preds = pipeline.predict(test_inputs)\n",
        "\n",
        "f1_train = f1_score(train_level, train_preds, average='macro')\n",
        "f1_val = f1_score(val_level, val_preds, average='macro')\n",
        "f1_test = f1_score(test_labels, test_preds, average='macro')\n",
        "print(f\"F1 Score on Training Set: {f1_train}\")\n",
        "print(f\"F1 Score on Validation Set: {f1_val}\")\n",
        "print(f\"F1 Score on Test Set: {f1_test}\")\n",
        "\n",
        "accuracy = accuracy_score(test_labels, test_preds)\n",
        "recall = recall_score(test_labels, test_preds, average='macro')\n",
        "precision = precision_score(test_labels, test_preds, average='macro')\n",
        "conf_matrix = confusion_matrix(test_labels, test_preds)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", classification_report(test_labels, test_preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJqY5WVHivHm",
        "outputId": "68763089-78c4-4719-8a8a-085066728d2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:406: UserWarning:\n",
            "\n",
            "Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'becaus', 'befor', 'could', 'dure', 'far', 'hi', 'might', 'must', 'need', 'onc', 'onli', 'ourselv', 'sha', 'themselv', 'thi', 'veri', 'whi', 'win', 'would'] not in stop_words.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning:\n",
            "\n",
            "'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score on Training Set: 0.822537223305816\n",
            "F1 Score on Validation Set: 0.5376095657901403\n",
            "F1 Score on Test Set: 0.5718583315553659\n",
            "Accuracy: 0.6029411764705882\n",
            "Recall: 0.5989032901296112\n",
            "Precision: 0.5615384615384615\n",
            "Confusion Matrix:\n",
            " [[10  6  1]\n",
            " [12 30 17]\n",
            " [ 4 14 42]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.38      0.59      0.47        17\n",
            "           1       0.60      0.51      0.55        59\n",
            "           2       0.70      0.70      0.70        60\n",
            "\n",
            "    accuracy                           0.60       136\n",
            "   macro avg       0.56      0.60      0.57       136\n",
            "weighted avg       0.62      0.60      0.61       136\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "english_stopwords = list(stopwords.words('english'))\n",
        "tfidf_params = {\n",
        "    'tfidf__lowercase': [True],\n",
        "    'tfidf__ngram_range': [(1, 2)],\n",
        "    'tfidf__max_features': [1000],\n",
        "    'tfidf__stop_words': [english_stopwords],\n",
        "    'tfidf__preprocessor': [preprocessor, lemmatize_text_spacy, lemmatize_and_stem]\n",
        "}\n",
        "\n",
        "logistic_params = {\n",
        "    'logistic__C': [0.001, 0.01, 0.1, 1.0, 10.0],\n",
        "    'logistic__solver': ['lbfgs'],\n",
        "    'logistic__multi_class': ['multinomial'],\n",
        "    'logistic__class_weight': ['balanced']\n",
        "}\n",
        "\n",
        "param_grid = {**tfidf_params, **logistic_params}\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('logistic', LogisticRegression(max_iter=500))\n",
        "])\n",
        "\n",
        "grid_search = GridSearchCV(pipeline, param_grid, scoring='f1_macro', cv=5, verbose=2, error_score='raise')\n",
        "\n",
        "grid_search.fit(train_inputs, train_level)\n",
        "print(\"Best combination of parameters are:\")\n",
        "print(grid_search.best_params_)\n",
        "print(f\"Best F1 score: {grid_search.best_score_}\")\n",
        "\n",
        "y_pred = grid_search.predict(val_inputs)\n",
        "f1 = f1_score(val_level, y_pred, average='macro')\n",
        "print(f\"Validation F1 score: {f1}\")\n"
      ],
      "metadata": {
        "id": "PQId0CVeiI8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Support Vector Machines"
      ],
      "metadata": {
        "id": "7AUyidLEjw2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stem_text(text):\n",
        "    words = nltk.word_tokenize(text)\n",
        "    stemmed_words = [stemmer.stem(word) for word in words]\n",
        "    return ' '.join(stemmed_words)\n",
        "\n",
        "tfidf_params = {\n",
        "    'lowercase': True,\n",
        "    'max_features': 2000,\n",
        "    'ngram_range': (1, 1),\n",
        "    'stop_words': english_stopwords,\n",
        "    'preprocessor': stem_text\n",
        "}\n",
        "\n",
        "svm_params = {\n",
        "    'C': 1,\n",
        "    'class_weight': 'balanced',\n",
        "    'gamma': 'scale',\n",
        "    'kernel': 'linear'\n",
        "}\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(**tfidf_params)),\n",
        "    ('svm', SVC(**svm_params))\n",
        "])\n",
        "\n",
        "pipeline.fit(train_inputs, train_level)\n",
        "dump(pipeline, 'trained_model.joblib')\n",
        "\n",
        "train_preds = pipeline.predict(train_inputs)\n",
        "val_preds = pipeline.predict(val_inputs)\n",
        "test_preds = pipeline.predict(test_inputs)\n",
        "\n",
        "f1_train = f1_score(train_level, train_preds, average='macro')\n",
        "f1_val = f1_score(val_level, val_preds, average='macro')\n",
        "f1_test = f1_score(test_labels, test_preds, average='macro')\n",
        "print(f\"F1 Score on Training Set: {f1_train}\")\n",
        "print(f\"F1 Score on Validation Set: {f1_val}\")\n",
        "print(f\"F1 Score on Test Set: {f1_test}\")\n",
        "\n",
        "accuracy = accuracy_score(test_labels, test_preds)\n",
        "recall = recall_score(test_labels, test_preds, average='macro')\n",
        "precision = precision_score(test_labels, test_preds, average='macro')\n",
        "conf_matrix = confusion_matrix(test_labels, test_preds)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", classification_report(test_labels, test_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkHvkb4Ej09M",
        "outputId": "257e827c-6a70-4430-f7e2-cfcbece4589a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:406: UserWarning:\n",
            "\n",
            "Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'becaus', 'befor', 'could', 'doe', 'dure', 'ha', 'hi', 'might', 'must', 'need', 'onc', 'onli', 'ourselv', 'sha', 'themselv', 'thi', 'veri', 'wa', 'whi', 'wo', 'would', 'yourselv'] not in stop_words.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score on Training Set: 0.9674370563896248\n",
            "F1 Score on Validation Set: 0.5812636165577342\n",
            "F1 Score on Test Set: 0.5829737972795477\n",
            "Accuracy: 0.625\n",
            "Recall: 0.5742605516782984\n",
            "Precision: 0.5970601537765717\n",
            "Confusion Matrix:\n",
            " [[ 7  8  2]\n",
            " [ 6 39 14]\n",
            " [ 1 20 39]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.41      0.45        17\n",
            "           1       0.58      0.66      0.62        59\n",
            "           2       0.71      0.65      0.68        60\n",
            "\n",
            "    accuracy                           0.62       136\n",
            "   macro avg       0.60      0.57      0.58       136\n",
            "weighted avg       0.63      0.62      0.62       136\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatize_text(text):\n",
        "    doc = nlp(text)\n",
        "    lemmatized_words = [token.lemma_ for token in doc]\n",
        "    return ' '.join(lemmatized_words)\n",
        "\n",
        "tfidf_params = {\n",
        "    'lowercase': True,\n",
        "    'max_features': 2000,\n",
        "    'ngram_range': (1, 1),\n",
        "    'stop_words': english_stopwords,\n",
        "    'preprocessor': lemmatize_text\n",
        "}\n",
        "\n",
        "svm_params = {\n",
        "    'C': 1,\n",
        "    'class_weight': 'balanced',\n",
        "    'gamma': 'scale',\n",
        "    'kernel': 'linear'\n",
        "}\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(**tfidf_params)),\n",
        "    ('svm', SVC(**svm_params))\n",
        "])\n",
        "\n",
        "pipeline.fit(train_inputs, train_level)\n",
        "dump(pipeline, 'trained_model.joblib')\n",
        "\n",
        "train_preds = pipeline.predict(train_inputs)\n",
        "val_preds = pipeline.predict(val_inputs)\n",
        "test_preds = pipeline.predict(test_inputs)\n",
        "\n",
        "f1_train = f1_score(train_level, train_preds, average='macro')\n",
        "f1_val = f1_score(val_level, val_preds, average='macro')\n",
        "f1_test = f1_score(test_labels, test_preds, average='macro')\n",
        "print(f\"F1 Score on Training Set: {f1_train}\")\n",
        "print(f\"F1 Score on Validation Set: {f1_val}\")\n",
        "print(f\"F1 Score on Test Set: {f1_test}\")\n",
        "\n",
        "accuracy = accuracy_score(test_labels, test_preds)\n",
        "recall = recall_score(test_labels, test_preds, average='macro')\n",
        "precision = precision_score(test_labels, test_preds, average='macro')\n",
        "conf_matrix = confusion_matrix(test_labels, test_preds)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", classification_report(test_labels, test_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqE0X3mpkBG4",
        "outputId": "3e6fa977-1c80-4eb5-f0dc-6a1c310dd16a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:406: UserWarning:\n",
            "\n",
            "Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['could', 'far', 'might', 'must', 'need', 'sha', 'win', 'would'] not in stop_words.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score on Training Set: 0.9664221640855178\n",
            "F1 Score on Validation Set: 0.5996681823767974\n",
            "F1 Score on Test Set: 0.5063659854357528\n",
            "Accuracy: 0.5514705882352942\n",
            "Recall: 0.5044643846239061\n",
            "Precision: 0.5145238095238095\n",
            "Confusion Matrix:\n",
            " [[ 6  9  2]\n",
            " [ 6 37 16]\n",
            " [ 4 24 32]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.38      0.35      0.36        17\n",
            "           1       0.53      0.63      0.57        59\n",
            "           2       0.64      0.53      0.58        60\n",
            "\n",
            "    accuracy                           0.55       136\n",
            "   macro avg       0.51      0.50      0.51       136\n",
            "weighted avg       0.56      0.55      0.55       136\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatize_and_stem(text):\n",
        "    doc = nlp(text)\n",
        "    lemmatized_words = [token.lemma_ for token in doc]\n",
        "\n",
        "    stemmed_words = [stemmer.stem(word) for word in lemmatized_words]\n",
        "    return ' '.join(stemmed_words)\n",
        "\n",
        "tfidf_params = {\n",
        "    'lowercase': True,\n",
        "    'max_features': 2000,\n",
        "    'ngram_range': (1, 1),\n",
        "    'stop_words': english_stopwords,\n",
        "    'preprocessor': lemmatize_and_stem\n",
        "}\n",
        "\n",
        "svm_params = {\n",
        "    'C': 1,\n",
        "    'class_weight': 'balanced',\n",
        "    'gamma': 'scale',\n",
        "    'kernel': 'linear'\n",
        "}\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(**tfidf_params)),\n",
        "    ('svm', SVC(**svm_params))\n",
        "])\n",
        "\n",
        "pipeline.fit(train_inputs, train_level)\n",
        "dump(pipeline, 'trained_model.joblib')\n",
        "\n",
        "train_preds = pipeline.predict(train_inputs)\n",
        "val_preds = pipeline.predict(val_inputs)\n",
        "test_preds = pipeline.predict(test_inputs)\n",
        "\n",
        "f1_train = f1_score(train_level, train_preds, average='macro')\n",
        "f1_val = f1_score(val_level, val_preds, average='macro')\n",
        "f1_test = f1_score(test_labels, test_preds, average='macro')\n",
        "print(f\"F1 Score on Training Set: {f1_train}\")\n",
        "print(f\"F1 Score on Validation Set: {f1_val}\")\n",
        "print(f\"F1 Score on Test Set: {f1_test}\")\n",
        "\n",
        "accuracy = accuracy_score(test_labels, test_preds)\n",
        "recall = recall_score(test_labels, test_preds, average='macro')\n",
        "precision = precision_score(test_labels, test_preds, average='macro')\n",
        "conf_matrix = confusion_matrix(test_labels, test_preds)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", classification_report(test_labels, test_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9moCLzYkJ1f",
        "outputId": "cd78cc60-b2f1-46cd-8d14-c704fc7404a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:406: UserWarning:\n",
            "\n",
            "Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'becaus', 'befor', 'could', 'dure', 'far', 'hi', 'might', 'must', 'need', 'onc', 'onli', 'ourselv', 'sha', 'themselv', 'thi', 'veri', 'whi', 'win', 'would'] not in stop_words.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score on Training Set: 0.9616564314238731\n",
            "F1 Score on Validation Set: 0.6121048762558197\n",
            "F1 Score on Test Set: 0.5691433566433567\n",
            "Accuracy: 0.6102941176470589\n",
            "Recall: 0.563243602525756\n",
            "Precision: 0.5833489827856025\n",
            "Confusion Matrix:\n",
            " [[ 7  9  1]\n",
            " [ 6 40 13]\n",
            " [ 2 22 36]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.41      0.44        17\n",
            "           1       0.56      0.68      0.62        59\n",
            "           2       0.72      0.60      0.65        60\n",
            "\n",
            "    accuracy                           0.61       136\n",
            "   macro avg       0.58      0.56      0.57       136\n",
            "weighted avg       0.62      0.61      0.61       136\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results after stemming, lemmatization or both together are below :\n",
        "\n",
        "**Logistic Regression**\n",
        "\n",
        "| **Preprocessing**          | **Training Set** | **Validation Set** | **Test Set** |\n",
        "|----------------------------|------------------|--------------------|--------------|\n",
        "| Baseline                   | 0.542            | 0.519              | 0.589        |\n",
        "| Stemming                   | 0.818            | 0.531              | 0.566        |\n",
        "| Lemmatization              | 0.841            | 0.561              | 0.548        |\n",
        "| Stemming + Lemmatization   | 0.823            | 0.538              | 0.572        |\n",
        "\n",
        "\n",
        "**SVM**\n",
        "\n",
        "| **Preprocessing**          | **Training Set** | **Validation Set** | **Test Set** |\n",
        "|----------------------------|------------------|--------------------|--------------|\n",
        "| Baseline                   | 0.538            | 0.545              | 0.580        |\n",
        "| Stemming                   | 0.967            | 0.581              | 0.583        |\n",
        "| Lemmatization              | 0.966            | 0.600              | 0.506        |\n",
        "| Stemming + Lemmatization   | 0.962            | 0.612              | 0.569        |\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The provided tables offer valuable insights into the performance of Logistic Regression and SVM models across various preprocessing techniques (baseline, stemming, lemmatization, and a combination of both) on training, validation, and test sets. For Logistic Regression, the baseline model shows moderate performance with F1 scores around 0.54-0.59, indicating reasonable generalization. Stemming significantly improves training performance (F1 = 0.818) but leads to overfitting, as validation and test scores drop to 0.531 and 0.566, respectively. In contrast, lemmatization delivers the best results among the preprocessing methods, achieving F1 scores of 0.841, 0.561, and 0.548 on the training, validation, and test sets, suggesting better generalization than stemming. The combination of both techniques yields moderate results, with training, validation, and test scores of 0.823, 0.538, and 0.572, respectively, indicating a balance between generalization and overfitting. For SVM, the baseline model maintains consistent performance (F1 around 0.54-0.58), reflecting a well-balanced fit. However, stemming leads to significant overfitting, producing a very high training F1 score (0.967) while validation and test scores fall to 0.581 and 0.583. Lemmatization also shows high training performance (0.966) but exhibits poor generalization with a test score of 0.506. The combination of stemming and lemmatization provides a slight improvement in generalization, with validation and test scores of 0.612 and 0.569, respectively. Overall, lemmatization and the combination of both methods appear to enhance generalization, while stemming alone tends to result in overfitting, especially within the SVM model.\n"
      ],
      "metadata": {
        "id": "1E6DiPLmkoTM"
      }
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOsyYiH13PfMA3yqLBfGZH3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}